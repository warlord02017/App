{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CIS_522_Homework 4 –_Student_Version",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/warlord02017/App/blob/main/Week5_homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhzzdfoH8O34"
      },
      "source": [
        "# CIS-522 Homework 4\n",
        "\n",
        "\n",
        "**Instructor:** Lyle Ungar\n",
        "\n",
        "**Content Creators:** Jordan Lei\n",
        "\n",
        "**Content Reviewers:** Kavish Shah, Ann-Katrin Reuel\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_VqTwG09NEn",
        "cellView": "form"
      },
      "source": [
        "#@markdown What is your Pennkey and pod? (text, not numbers, e.g. bfranklin)\n",
        "my_pennkey = 'sashankv' #@param {type:\"string\"}\n",
        "my_pod = 'the-weekenders' #@param ['Select', 'upain', 'ah-damn-optimizer', 'backpropagandists', 'backpropers','excel-erators','GAN-gsters','han-not-solo','hufflefluffs','lets-taco-bout-it','natural-networkers','pytorture','sigmoids','strong-signals','the-denominators','the-travellers', 'the-weekenders', 'tomorrows-incredibles', 'brute-force']\n",
        "my_email = 'sashankv@seas.upenn.edu' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# start timing\n",
        "import time\n",
        "try:t0;\n",
        "except NameError: t0 = time.time()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPBNHacqXkrC",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf1a2dd-4c20-4758-833d-f1f5cd3aac56"
      },
      "source": [
        "#@markdown Run this cell for imports. It should print \"cuda\"\n",
        "#@markdown \n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import pathlib\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "torch.manual_seed(2021)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qzHTBpz9hy4"
      },
      "source": [
        "# Part 1. Attack!\n",
        "In this homework, you will implement a simple adversarial attack on a neural network trained on MNIST handwritten digits. It might sound complicated, but we'll guide you through it. First, let's download and familiarize ourselves with the dataset. \n",
        "\n",
        "**Run the cell below. Do not modify.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQAEcBpEXsAf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "bf7d4b86-8c97-4ea1-97d9-69fb125a0860"
      },
      "source": [
        "dataset = datasets.MNIST(\"/content/\", download = True, train = True, transform = transforms.ToTensor())\n",
        "\n",
        "len_train = int(0.8 * len(dataset))\n",
        "len_val = len(dataset) - len_train\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [len_train, len_val])\n",
        "\n",
        "#train_loader is the data loader containing the training samples\n",
        "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
        "#val_loader is the data loader containing the validation samples\n",
        "val_loader = DataLoader(val_dataset, batch_size = 64, shuffle = True)\n",
        "\n",
        "#visualize one of the elements\n",
        "base_image = dataset[0][0].reshape(1, 784)\n",
        "plt.imshow(base_image.reshape(28, 28).numpy())\n",
        "plt.show()\n",
        "print(\"Above, I have an image with the corresponding label:\", dataset[0][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Above, I have an image with the corresponding label: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6FxzcrN_gvi"
      },
      "source": [
        "## 1.1 Network\n",
        "MNIST digits come in images of size 28 x 28, and have an output of size 10. Let's construct a simple feedforward network with a *single hidden layer of size 64*. That is, our network should be shape *input --> 64 --> output*, with ReLU activations after each layer.\n",
        "\n",
        "**Your turn. Fill in the missing parts of the network definition. Don't forget to define a forward() function.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ujcd6N4cXNU"
      },
      "source": [
        "class Net1(nn.Module): \n",
        "    def __init__(self):\n",
        "        super(Net1, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8I07IF7uBoyn"
      },
      "source": [
        "## 1.2 Define Functions\n",
        "Now we want to define `train` and `test` functions to train and test our network, respectively. Fill in the \"TODO\" sections below for the train and test functions. \n",
        "\n",
        "**Your turn. Fill in the missing parts of the `train` and `test` functions. Don't forget to zero out the gradients, reshape the MNIST images and send them to the GPU for processing.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9flZGP5jdtKX"
      },
      "source": [
        "def train(train_loader, net, optimizer, criterion, epochs = 10):\n",
        "  for epoch in range(epochs): \n",
        "    c = 0\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    for i, (image, label) in enumerate(train_loader):\n",
        "      #TODO: complete the training function (zero out gradients, reshape MNIST images)\n",
        "      optimizer.zero_grad()\n",
        "      image = torch.flatten(image,start_dim=1)\n",
        "      image = image.to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      #TODO: define prediction\n",
        "      prediction = net(image)\n",
        "\n",
        "      #calculate the loss\n",
        "      loss = criterion(prediction,label) \n",
        "      \n",
        "      #TODO: complete the training function\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      #TODO: define the predicted class\n",
        "      predicted_class = prediction.argmax(dim=1)\n",
        "\n",
        "      correct = torch.sum((predicted_class == label))\n",
        "      total_loss += loss\n",
        "      total_correct += correct\n",
        "      c += len(label)\n",
        "\n",
        "      if i%500 == 0:\n",
        "        print(\"[Epoch %s]\\tAcc:%.4f\\tLoss:%.4f\"%(epoch, (total_correct/c).item(), (total_loss/c).item()))\n",
        "\n",
        "\n",
        "def test(test_loader, net, criterion): \n",
        "  c = 0\n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "  for i, (image, label) in enumerate(test_loader):\n",
        "    #TODO: reshape images and send them to the GPU as above \n",
        "    image = torch.flatten(image,start_dim=1)\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "    #TODO: use your network to make a prediction\n",
        "    prediction = net(image) \n",
        "\n",
        "    #TODO: calculate the loss \n",
        "    loss = criterion(prediction,label)\n",
        "    \n",
        "    #TODO: complete the code\n",
        "    predicted_class = prediction.argmax(dim=1)\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_correct += torch.sum((predicted_class == label)).item()\n",
        "    c += len(label)\n",
        "\n",
        "  return total_loss/c, total_correct/c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnSgXRsZC2tE"
      },
      "source": [
        "## 1.3 Train the Network\n",
        "Now let's train the network. Define the following: \n",
        "* `net`: initialize the network with the `Net1` class. Make sure you send the network to cuda!\n",
        "* `optimizer`: use an Adam optimizer with learning rate 0.01, and initialize it with your network parameters.\n",
        "* `criterion`: choose a good criterion for this task. Consider looking at: https://pytorch.org/docs/stable/nn.html#loss-function. \n",
        "\n",
        "**Your turn. Define the net, optimizer, and criterion. Don't forget to send the net to the device.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-NzkD3reJBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a4a509-149b-4800-e289-3b5daa908455"
      },
      "source": [
        "#TODO: define net, send it to device\n",
        "torch.manual_seed(1998)\n",
        "net = Net1()\n",
        "net = net.to(device) \n",
        "#TODO: define optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.01) \n",
        "#TODO: choose a good criterion\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "\n",
        "train(train_loader, net, optimizer, criterion)\n",
        "loss, accuracy = test(val_loader, net, criterion)\n",
        "print(\"Evaluation\\n\\tTest Loss: %.4f\\tTest Accuracy: %.2f%%\"%(loss, accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0]\tAcc:0.0469\tLoss:0.0361\n",
            "[Epoch 0]\tAcc:0.6580\tLoss:0.0144\n",
            "[Epoch 1]\tAcc:0.7344\tLoss:0.0106\n",
            "[Epoch 1]\tAcc:0.6823\tLoss:0.0124\n",
            "[Epoch 2]\tAcc:0.7500\tLoss:0.0093\n",
            "[Epoch 2]\tAcc:0.6849\tLoss:0.0122\n",
            "[Epoch 3]\tAcc:0.6719\tLoss:0.0119\n",
            "[Epoch 3]\tAcc:0.6848\tLoss:0.0121\n",
            "[Epoch 4]\tAcc:0.6094\tLoss:0.0143\n",
            "[Epoch 4]\tAcc:0.6907\tLoss:0.0118\n",
            "[Epoch 5]\tAcc:0.7031\tLoss:0.0115\n",
            "[Epoch 5]\tAcc:0.6878\tLoss:0.0118\n",
            "[Epoch 6]\tAcc:0.7188\tLoss:0.0114\n",
            "[Epoch 6]\tAcc:0.6915\tLoss:0.0117\n",
            "[Epoch 7]\tAcc:0.8125\tLoss:0.0096\n",
            "[Epoch 7]\tAcc:0.7747\tLoss:0.0090\n",
            "[Epoch 8]\tAcc:0.7812\tLoss:0.0083\n",
            "[Epoch 8]\tAcc:0.7835\tLoss:0.0085\n",
            "[Epoch 9]\tAcc:0.7656\tLoss:0.0086\n",
            "[Epoch 9]\tAcc:0.7820\tLoss:0.0086\n",
            "Evaluation\n",
            "\tTest Loss: 0.0098\tTest Accuracy: 77.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvd1KRvsD0kR"
      },
      "source": [
        "## 1.4 How Did We Do? \n",
        "Now let's see how our network performs on the image we showed above! Run the cell below. \n",
        "**Run the cell below. Do not modify**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPdKnz0jqwv3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b42a8615-aed5-444a-c997-53496354f7fd"
      },
      "source": [
        "base_image = dataset[0][0].reshape(1, 784)\n",
        "plt.imshow(base_image.reshape(28, 28).numpy())\n",
        "plt.show()\n",
        "net_prediction = torch.argmax(net(base_image.to(device))).item()\n",
        "print(\"My Network Predicts That This Number Is... %s\"%(net_prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My Network Predicts That This Number Is... 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgl5l7zgEniR"
      },
      "source": [
        "## 1.5 Adversarial Attack\n",
        "Now for the fun part. Let's attack our network by creating an image that looks almost exactly like the one above, but makes it mistake the digit for a 3! How do we do that? \n",
        "\n",
        "Here's one way of doing it: instead of updating the **weights of our network**, what if we updated the **pixels of our image** using gradient descent? Take a moment to read that again. We're going to require gradients on our **image**, and then update it until the network is properly fooled!\n",
        "\n",
        "Our problem is complex though. We have two goals: \n",
        "\n",
        "\n",
        "1.   `criterion_1`: We want to fool the network into thinking that the image is a 3, not a 5. \n",
        "2.   `criterion_2`: We want to make sure the modified image `mod_image` looks as much like the original `base_image` as possible.\n",
        "\n",
        "Our loss will be a weighted sum between the losses evaluated on these two criteria, i.e. `loss = weight_1 * loss_1 + weight_2 * loss_2`. For our code below, let `weight_1 = 0.001` and `weight_2 = 1`.\n",
        "\n",
        "**Your turn. Define `criterion_1`, `criterion_2`, `loss_1`, `loss_2`, and `loss`. Run the code; if your attack is successful it will print \"ATTACK SUCCESSFUL\"**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfMq1XOmrWja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a037e0-52f8-4929-a145-b36ba5b4f0dc"
      },
      "source": [
        "#create a copy of base_image which we can modify\n",
        "mod_image = base_image.clone() \n",
        "#our target class is 3. We send this to the device\n",
        "target = torch.LongTensor([3]).to(device)\n",
        "optimizer = optim.SGD([mod_image.requires_grad_(True)], lr = 0.01)\n",
        "\n",
        "#Choose a good criterion to compare our prediction with the target\n",
        "criterion1 = nn.CrossEntropyLoss()\n",
        "\n",
        "#Choose a good criterion which describes how \"far off\" our mod_image\n",
        "#is from the base_image\n",
        "criterion2 = nn.KLDivLoss() #TODO: choose criterion2\n",
        "\n",
        "\n",
        "for i in range(10000):\n",
        "  prediction = net(mod_image.to(device))\n",
        "\n",
        "  #loss_1 is the result of evaluating criterion_1 on the prediction of the net\n",
        "  #compared to the target class.\n",
        "  loss_1 = criterion1(prediction,target) #TODO: define loss_1\n",
        "\n",
        "  #loss_2 is the result of evaluating criterion_2 on the current image\n",
        "  #(mod_image) compared to the original image (base_image).\n",
        "  loss_2 = criterion2(mod_image,base_image) #TODO: define loss_2\n",
        "\n",
        "  #the final loss is a weighted sum of the losses, where weight_1 = 0.001 and weight_2 = 1\n",
        "  loss = 0.001*loss_1 + 1*loss_2 #TODO: define loss\n",
        "  \n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step() #complete the training\n",
        "\n",
        "  predicted_class = prediction.argmax(dim=1)\n",
        "\n",
        "  if predicted_class == target:\n",
        "    print(\"Predicted Class: %s, Loss: %s, ATTACK SUCCESSFUL!\"%(predicted_class.item(), loss.item()))\n",
        "    break\n",
        "  else:\n",
        "    if i%10 == 0: \n",
        "      print(\"Predicted Class: %s, Loss: %s\"%(predicted_class.item(), loss.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 5, Loss: -0.14721304178237915\n",
            "Predicted Class: 5, Loss: -0.1473853439092636\n",
            "Predicted Class: 5, Loss: -0.1475410908460617\n",
            "Predicted Class: 5, Loss: -0.14768078923225403\n",
            "Predicted Class: 5, Loss: -0.14780542254447937\n",
            "Predicted Class: 5, Loss: -0.1479162722826004\n",
            "Predicted Class: 5, Loss: -0.14801472425460815\n",
            "Predicted Class: 3, Loss: -0.14808551967144012, ATTACK SUCCESSFUL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2748: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXk8bNKbSK6A"
      },
      "source": [
        "So what does our image look like now? Run the cell below to compare the original input to the modified image, and how our network classifies each. Did we succeed?\n",
        "\n",
        "**Take a screenshot of the output of this cell and save it for later.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-K_6lmVTub3z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "1ea5b8e0-3ee9-4fbd-f89d-ddd6ebea8927"
      },
      "source": [
        "#@markdown Run this cell to display your adversarial attack!\n",
        "net.eval()\n",
        "plt.imshow(base_image.reshape(28, 28).detach().numpy())\n",
        "plt.show()\n",
        "net_prediction = torch.argmax(net(base_image.to(device))).item()\n",
        "print(\"My Network Predicts That This Number Is... %s\"%(net_prediction))\n",
        "plt.imshow(mod_image.reshape(28, 28).detach().numpy())\n",
        "plt.show()\n",
        "net_prediction = torch.argmax(net(mod_image.to(device))).item()\n",
        "print(\"My Network Predicts That This Number Is... %s\"%(net_prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My Network Predicts That This Number Is... 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My Network Predicts That This Number Is... 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVjcgCYTS0Oc"
      },
      "source": [
        "# Part 2. Defend!\n",
        "In this next part of the homework, we will ask you to use **regularization** to defend against the adversarial image you constructed in part 1. Try each of the following regularization techniques: \n",
        "* Early stopping\n",
        "* Dropout (https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html)\n",
        "* L2 regularization (hint: see the `weight_decay` parameter in optim.Adam: https://pytorch.org/docs/stable/optim.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBsKM_pJe1gN"
      },
      "source": [
        "## 2.1 Train your Defense\n",
        "In this section, you'll train a network which will be able to detect that the adversarial image is a 5, not a 3.\n",
        "**Make sure your network is exactly the same architecture as you had (with the exception of adding dropout layers)!**\n",
        "\n",
        "**Your turn. Train your network on each regularization technique below. We recommend that you try each technique individually, and then combine them if necessary. Once your net completes training, you may test it on the adversarial image in the following section.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLtb_EYauifN"
      },
      "source": [
        "#Net2 should be the same architecture as Net1 with the exception of dropout layers\n",
        "class Net2(nn.Module): \n",
        "    def __init__(self):\n",
        "        super(Net2, self).__init__()\n",
        "        self.fc1 = nn.Linear(28*28, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUlHTpWKTDA8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "106f8592-bfc0-4814-a3fa-3349e26dacab"
      },
      "source": [
        "#TODO: define net\n",
        "torch.manual_seed(2021)\n",
        "net = Net2().to(device)\n",
        "#TODO: define optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.01, weight_decay= 0.01) \n",
        "#TODO: choose a good criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train(train_loader, net, optimizer, criterion)\n",
        "loss, accuracy = test(val_loader, net, criterion)\n",
        "print(\"Evaluation\\n\\tTest Loss: %.4f\\tTest Accuracy: %.2f%%\"%(loss, accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0]\tAcc:0.1875\tLoss:0.0358\n",
            "[Epoch 0]\tAcc:0.3433\tLoss:0.0289\n",
            "[Epoch 1]\tAcc:0.3594\tLoss:0.0269\n",
            "[Epoch 1]\tAcc:0.3587\tLoss:0.0283\n",
            "[Epoch 2]\tAcc:0.3438\tLoss:0.0319\n",
            "[Epoch 2]\tAcc:0.3700\tLoss:0.0282\n",
            "[Epoch 3]\tAcc:0.3750\tLoss:0.0283\n",
            "[Epoch 3]\tAcc:0.3735\tLoss:0.0281\n",
            "[Epoch 4]\tAcc:0.4062\tLoss:0.0271\n",
            "[Epoch 4]\tAcc:0.3666\tLoss:0.0283\n",
            "[Epoch 5]\tAcc:0.3594\tLoss:0.0300\n",
            "[Epoch 5]\tAcc:0.3661\tLoss:0.0283\n",
            "[Epoch 6]\tAcc:0.3594\tLoss:0.0273\n",
            "[Epoch 6]\tAcc:0.3744\tLoss:0.0280\n",
            "[Epoch 7]\tAcc:0.4375\tLoss:0.0251\n",
            "[Epoch 7]\tAcc:0.3687\tLoss:0.0281\n",
            "[Epoch 8]\tAcc:0.4062\tLoss:0.0255\n",
            "[Epoch 8]\tAcc:0.3721\tLoss:0.0280\n",
            "[Epoch 9]\tAcc:0.4219\tLoss:0.0258\n",
            "[Epoch 9]\tAcc:0.3764\tLoss:0.0278\n",
            "Evaluation\n",
            "\tTest Loss: 0.0283\tTest Accuracy: 35.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IarN6lE2dvcC"
      },
      "source": [
        "## 2.2 How Did We Do?\n",
        "Run the code below to test if your regularization worked. If successful, it will print \"DEFENSE SUCCESSFUL\". \n",
        "\n",
        "**Run the code below. Do not modify. If successful, take a screenshot and write down what regularization parameters led to your success**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "MMtdWWryTbB-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "7f573355-cdc0-4824-f4fa-23c418ea710e"
      },
      "source": [
        "#@markdown Run this cell to test your defense!\n",
        "net.eval()\n",
        "\n",
        "plt.imshow(base_image.reshape(28, 28).detach().numpy())\n",
        "plt.show()\n",
        "prediction_orig = net(mod_image.to(device))\n",
        "net_predicted_class_orig = torch.argmax(prediction_orig).item()\n",
        "print(\"My Regularized Network Predicts That This Number Is... %s\"%(net_predicted_class_orig))\n",
        "plt.imshow(mod_image.reshape(28, 28).detach().numpy())\n",
        "plt.show()\n",
        "\n",
        "prediction = net(mod_image.to(device))\n",
        "net_predicted_class = torch.argmax(prediction).item()\n",
        "print(\"My Regularized Network Predicts That This Number Is... %s\"%(net_predicted_class))\n",
        "if net_predicted_class_orig == 5 and net_predicted_class == 5: \n",
        "  print(\"DEFENSE SUCCESSFUL!\")\n",
        "  saved_prediction = prediction\n",
        "else: \n",
        "  print(\"AW, SNAP! FOOLED AGAIN! GO BACK AND TRY A DIFFERENT REGULARIZATION COMBO\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My Regularized Network Predicts That This Number Is... 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My Regularized Network Predicts That This Number Is... 5\n",
            "DEFENSE SUCCESSFUL!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_e1Vj4cufg93"
      },
      "source": [
        "**Write answers to the following questions below**\n",
        "1. How did your regularized models compare to your original model, in terms of overall accuracy? How did they compare to one another?\n",
        "2. Did your regularized models successfully defend against the adversarial task? If so, what parameters contributed to your success? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwEIFfWFeoFP"
      },
      "source": [
        "#Remove starter text and write your answer.\n",
        "reflection_1 = '''The regularized model did not do well as compared to our original model in terms of overall accuracy.\n",
        "For the regularized model, we got a test accuracy of 39.82%. For our original model, we got a test accuracy of 84.96%.\n",
        "'''\n",
        "refletion_2 = '''Yes, the regularized models successfully defend against the adversarial task'''\n",
        "reflection_3 = '''The parameters that contributed to this success was using dropout with p=0.5 after each layer and also L2 regularization with weight_decay of 0.005'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1KoSvRJHvor"
      },
      "source": [
        "# Part 3. Deep Learning, Deeper Thinking\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29bQF6U__uxX"
      },
      "source": [
        "Now that you've gotten familiar with adversarial attacks and regularization, it's time to think about some of the implications of these attacks. First, read the following papers/articles.\n",
        "\n",
        "* https://openai.com/blog/adversarial-example-research/\n",
        "* https://www.sciencedirect.com/science/article/pii/S0743731518309183\n",
        "(accessible through Penn Libraries)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA9V9UtVQF2C"
      },
      "source": [
        "## Part 3.1 Reflect\n",
        "**Short answer: What type of adversarial attack did we conduct in section 1.5 (choose the most similar one based on the descriptions in the second paper)?**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reflection_1 = 'The type of adversarial attack that we conducted in section 1.5 based on the descriptions in the second paper is: Fast gradient sign method (FGSM). This is because we add noise to our image (that has the label as 5) along the gradient directions to make it seem like it has label 3. Which is exactly similar to what is described for FGSM. ' #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "owkH0p_g7SIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_u3T9h6QAMo"
      },
      "source": [
        "## Part 3.1 Discuss\n",
        "**In 150-300 words, please answer the following questions, and also post these to Slack**\n",
        "* As engineers, how can we safeguard against adversarial attacks? Give a real-world example of what an adversarial attack might look like (aside from the one you just deployed and the one we showed you in the worksheets), and what consequences it might have.\n",
        "* How might adversarial attacks on machine learning algorithms impact public trust of these algorithms? How might we communicate these risks to the public? \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reflection_2 = 'As engineers, we can safeguard against adversarial attacks by making use of the techniques as described in the HW, which is essentially by making use of regularization techniques such as early stopping, dropout and L2 regularization. A real world example of such an attack could be to fool smart home devices to gain un-authorized access to homes of other people or in the opposite case \\u2013 deny access to authorized persons. A similar attack could also be used to fool facial recognition systems that are used to unlock phones these days and gain unauthorized access to them. Consequences of these attacks are very severe since they pose safety hazards, since unauthorized people would be able to get into our homes and our phones. Adversarial attacks on machine learning algorithms will have public lose faith in these systems and lose confidence in the reliability of these systems. Therefore, we should take all measures to prevent them as much as possible. These risks can be communicated to the public either by digital campaigns or disclaimers while they purchase these products that could potentially be attacked in this way. Giving ability to manually override these systems would also help mitigate the damage that could potentially be done and give confidence to the users.' #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "qtgpqAxp7U80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7wWXWiLBhrD"
      },
      "source": [
        "# Part 4. Rethinking Generalization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLAtJonqBrb0"
      },
      "source": [
        "Read the first three pages of this article on \"Understanding Deep Learning Requires Rethinking Generalization\" [https://arxiv.org/pdf/1611.03530.pdf] and Answer the following questions:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt2nFHMfCzWu"
      },
      "source": [
        "1. Why is it important that neural nets can learn to get zero training error on \n",
        "images with randomized labels, or even on images that are pure random noise?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reflection_3 = 'The article explains that the importance of the fact that neural nets can learn to get zero training error on images with randomized labels, or even on images that are pure random noise is that it shows:   1.\\tNeural networks are capable enough to memorize the entire data set effectively. 2.\\tEven Optimizing on random labels is easy and can be done in a proportion of time that is only slightly greater than the amount of time required to train the network on true labels. 3.\\tIt shows that randomizing the target labels is simply just equivalent to a method of data transformation, leaving all other properties of the learning problem unchanged.  Also, it shows that by randomizing labels alone we can force the generalization error of a model to jump up considerably without changing the model, its size, hyperparameters, or the optimizer because successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. ' #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DtLLCRRe7atG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrARQcJrDHXy"
      },
      "source": [
        "2. How many weights are needed in a 2-layer ReLU to fit n observations each of dimension d?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reflection_4 = 'p = (2n + d) parameters are required to fit n observations each of dimension d.' #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kzpij1kk7dwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrdJkZ-zDc-3"
      },
      "source": [
        "3. Are standard regularization methods (e.g. L1, L2, early stopping) required to prevent overfitting?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reflection_5 = 'The article explains that standard explicit regularization in neural networks does not necessarily improve generalization performance nor is sufficient by itself to control generalization error. This is directly in contrast with convex empirical risk minimization where explicit regularization is necessary to rule out trivial solutions. However, things work differently in deep learning where absence of all regularization explicitly does not necessarily imply poor generalization error.' #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ArGwRONy7f8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH8mN2tyDsM7"
      },
      "source": [
        "4. The authors argue that “implicit regularization” is more important than explicit regularization. What do they mean by “implicit regularization” and how does it work?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reflection_6 = 'Neural networks have a kind of regularization that is imparted by virtue of their design\\u2014such as using SGD for gradient descent. SGD acts as one of the implicit regularizers in the network. In linear models especially, using SGD always leads to a solution with smaller norm values. Hence, this proves that SGD acts as implicit regularization. This is primarily because of the noise that is added as a consequence of using SGD, since gradients are updated for each data point individually. This leads to more noise and therefore imparts exploratory tendencies in the search which is a form of regularization.' #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "K4oz0KX67imz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU_EUAJyQnBm"
      },
      "source": [
        "# Part 5. Better-Know-A-Pod\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WGPXvcdXpbX"
      },
      "source": [
        "**List 2 other members of your pod - not the same two that you listed in the last homeworks. What are they most excited about doing after the pandemic is over, and why? (around 100 words each).**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "better_know_your_pod = 'Kashyap from my pod said he would like to go to family get togethering and enjoy spending time with family all together . Due to pandemic different people in his family were struck at different places . So once the pandemic is over he would like to invite them all to a small function and talk for hours without wearing any mask. He is also exited to travel to the places in his bucket list like Canada , Europe and Middle East. I feel a lot of us share similar preferences as Kashyap. The pandemic has indeed forced families to be distant from each other over the past couple of years or so.  Joseph from my pod said he\\u2019s mostly looking forward to traveling. When the pandemic started he had just gotten back from a semester abroad in New Zealand, and  had made plans to spend time in Vietnam and Cambodia with friends during the summer of 2020. He still plans on taking a long trip once the pandemic is over, but is not sure where he\\u2019ll go. Could be SE Asia, South Africa, Argentina, or Kenya/Tanzania. As the social chair of the Graduate Association of Bioengineers, he\\u2019s also looking forward to being able to have in-person happy hours again.' #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KBUk69vG7oMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzdZmL_7gtjq"
      },
      "source": [
        "# Submission\n",
        "**Load the airtable below and submit your work.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRwrR_5VesBi",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "c58d1c57-de78-4fb7-eb37-fba75212f5f8"
      },
      "source": [
        "#@markdown #Run Cell to Show Airtable Form\n",
        "#@markdown ##**Confirm your answers and then click \"Submit\"**\n",
        "#@markdown If you're having issues with the Airtable submission, use this link: https://airtable.com/shrByNErdzJvcmsvi.\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import urllib.parse\n",
        "from IPython.display import IFrame\n",
        "def prefill_form(src, fields: dict):\n",
        "  '''\n",
        "  src: the original src url to embed the form\n",
        "  fields: a dictionary of field:value pairs,\n",
        "  e.g. {\"pennkey\": my_pennkey, \"location\": my_location}\n",
        "  '''\n",
        "  prefill_fields = {}\n",
        "  for key in fields:\n",
        "      new_key = 'prefill_' + key\n",
        "      prefill_fields[new_key] = fields[key]\n",
        "  prefills = urllib.parse.urlencode(prefill_fields)\n",
        "  src = src + prefills\n",
        "  return src\n",
        "\n",
        "#autofill fields if they are not present\n",
        "#a missing pennkey and pod will result in an Airtable warning\n",
        "#which is easily fixed user-side.\n",
        "try: my_pennkey;\n",
        "except NameError: my_pennkey = \"\"\n",
        "try: my_pod;\n",
        "except NameError: my_pod = \"Select\"\n",
        "try: my_email;\n",
        "except NameError: my_email = \"\"\n",
        "\n",
        "\n",
        "#autofill time if it is not present\n",
        "try: t0;\n",
        "except NameError: t0 = time.time()\n",
        "try: t1;\n",
        "except NameError: t1 = time.time()\n",
        "times = np.array([t1])-t0\n",
        "\n",
        "fields = {\"pennkey\": my_pennkey,\n",
        "          \"pod\": my_pod,\n",
        "          \"email\": my_email,\n",
        "          \"reflection_1\":reflection_1,\n",
        "          \"reflection_2\":reflection_2,\n",
        "          \"reflection_3\":reflection_3,\n",
        "          \"reflection_4\":reflection_4,\n",
        "          \"reflection_5\":reflection_5,\n",
        "          \"reflection_6\":reflection_6,\n",
        "          \"better_know_your_pod\":better_know_your_pod,\n",
        "          \"cumulative_times\": times}\n",
        "\n",
        "src = \"https://airtable.com/embed/shrByNErdzJvcmsvi?\"\n",
        "\n",
        "#now instead of the original source url, we do: src = prefill_form(src, fields)\n",
        "display(IFrame(src = prefill_form(src, fields), width = 800, height = 400))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"800\"\n",
              "            height=\"400\"\n",
              "            src=\"https://airtable.com/embed/shrByNErdzJvcmsvi?prefill_pennkey=sashankv&prefill_pod=the-weekenders&prefill_email=sashankv%40seas.upenn.edu&prefill_reflection_1=The+type+of+adversarial+attack+that+we+conducted+in+section+1.5+based+on+the+descriptions+in+the+second+paper+is%3A+Fast+gradient+sign+method+%28FGSM%29.+This+is+because+we+add+noise+to+our+image+%28that+has+the+label+as+5%29+along+the+gradient+directions+to+make+it+seem+like+it+has+label+3.+Which+is+exactly+similar+to+what+is+described+for+FGSM.+&prefill_reflection_2=As+engineers%2C+we+can+safeguard+against+adversarial+attacks+by+making+use+of+the+techniques+as+described+in+the+HW%2C+which+is+essentially+by+making+use+of+regularization+techniques+such+as+early+stopping%2C+dropout+and+L2+regularization.+A+real+world+example+of+such+an+attack+could+be+to+fool+smart+home+devices+to+gain+un-authorized+access+to+homes+of+other+people+or+in+the+opposite+case+%E2%80%93+deny+access+to+authorized+persons.+A+similar+attack+could+also+be+used+to+fool+facial+recognition+systems+that+are+used+to+unlock+phones+these+days+and+gain+unauthorized+access+to+them.+Consequences+of+these+attacks+are+very+severe+since+they+pose+safety+hazards%2C+since+unauthorized+people+would+be+able+to+get+into+our+homes+and+our+phones.+Adversarial+attacks+on+machine+learning+algorithms+will+have+public+lose+faith+in+these+systems+and+lose+confidence+in+the+reliability+of+these+systems.+Therefore%2C+we+should+take+all+measures+to+prevent+them+as+much+as+possible.+These+risks+can+be+communicated+to+the+public+either+by+digital+campaigns+or+disclaimers+while+they+purchase+these+products+that+could+potentially+be+attacked+in+this+way.+Giving+ability+to+manually+override+these+systems+would+also+help+mitigate+the+damage+that+could+potentially+be+done+and+give+confidence+to+the+users.&prefill_reflection_3=The+article+explains+that+the+importance+of+the+fact+that+neural+nets+can+learn+to+get+zero+training+error+on+images+with+randomized+labels%2C+or+even+on+images+that+are+pure+random+noise+is+that+it+shows%3A+++1.%09Neural+networks+are+capable+enough+to+memorize+the+entire+data+set+effectively.+2.%09Even+Optimizing+on+random+labels+is+easy+and+can+be+done+in+a+proportion+of+time+that+is+only+slightly+greater+than+the+amount+of+time+required+to+train+the+network+on+true+labels.+3.%09It+shows+that+randomizing+the+target+labels+is+simply+just+equivalent+to+a+method+of+data+transformation%2C+leaving+all+other+properties+of+the+learning+problem+unchanged.++Also%2C+it+shows+that+by+randomizing+labels+alone+we+can+force+the+generalization+error+of+a+model+to+jump+up+considerably+without+changing+the+model%2C+its+size%2C+hyperparameters%2C+or+the+optimizer+because+successful+deep+artificial+neural+networks+can+exhibit+a+remarkably+small+difference+between+training+and+test+performance.+&prefill_reflection_4=p+%3D+%282n+%2B+d%29+parameters+are+required+to+fit+n+observations+each+of+dimension+d.&prefill_reflection_5=The+article+explains+that+standard+explicit+regularization+in+neural+networks+does+not+necessarily+improve+generalization+performance+nor+is+sufficient+by+itself+to+control+generalization+error.+This+is+directly+in+contrast+with+convex+empirical+risk+minimization+where+explicit+regularization+is+necessary+to+rule+out+trivial+solutions.+However%2C+things+work+differently+in+deep+learning+where+absence+of+all+regularization+explicitly+does+not+necessarily+imply+poor+generalization+error.&prefill_reflection_6=Neural+networks+have+a+kind+of+regularization+that+is+imparted+by+virtue+of+their+design%E2%80%94such+as+using+SGD+for+gradient+descent.+SGD+acts+as+one+of+the+implicit+regularizers+in+the+network.+In+linear+models+especially%2C+using+SGD+always+leads+to+a+solution+with+smaller+norm+values.+Hence%2C+this+proves+that+SGD+acts+as+implicit+regularization.+This+is+primarily+because+of+the+noise+that+is+added+as+a+consequence+of+using+SGD%2C+since+gradients+are+updated+for+each+data+point+individually.+This+leads+to+more+noise+and+therefore+imparts+exploratory+tendencies+in+the+search+which+is+a+form+of+regularization.&prefill_better_know_your_pod=Kashyap+from+my+pod+said+he+would+like+to+go+to+family+get+togethering+and+enjoy+spending+time+with+family+all+together+.+Due+to+pandemic+different+people+in+his+family+were+struck+at+different+places+.+So+once+the+pandemic+is+over+he+would+like+to+invite+them+all+to+a+small+function+and+talk+for+hours+without+wearing+any+mask.+He+is+also+exited+to+travel+to+the+places+in+his+bucket+list+like+Canada+%2C+Europe+and+Middle+East.+I+feel+a+lot+of+us+share+similar+preferences+as+Kashyap.+The+pandemic+has+indeed+forced+families+to+be+distant+from+each+other+over+the+past+couple+of+years+or+so.++Joseph+from+my+pod+said+he%E2%80%99s+mostly+looking+forward+to+traveling.+When+the+pandemic+started+he+had+just+gotten+back+from+a+semester+abroad+in+New+Zealand%2C+and++had+made+plans+to+spend+time+in+Vietnam+and+Cambodia+with+friends+during+the+summer+of+2020.+He+still+plans+on+taking+a+long+trip+once+the+pandemic+is+over%2C+but+is+not+sure+where+he%E2%80%99ll+go.+Could+be+SE+Asia%2C+South+Africa%2C+Argentina%2C+or+Kenya%2FTanzania.+As+the+social+chair+of+the+Graduate+Association+of+Bioengineers%2C+he%E2%80%99s+also+looking+forward+to+being+able+to+have+in-person+happy+hours+again.&prefill_cumulative_times=%5B191.85449004%5D\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f799bad78d0>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SCPmqEnjTXaQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}